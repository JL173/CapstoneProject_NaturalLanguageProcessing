source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
base_1000 <- LoadFiles("data/en_US/", n = 1000)
setwd("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing")
base_1000 <- LoadFiles("data/en_US/", n = 1000)
library(tidyverse)
library(tidytext)
library(tm)
library(ggthemes)
library(openNLP)
base_1000 <- LoadFiles("data/en_US/", n = 1000)
base_1000[[3]]
new_list <- SplitDF(base_1000[[3]])
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
new_list <- SplitDF(base_1000[[3]])
object.size(base_1000[[3]])
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
base_10000 <- LoadFiles("data/en_US/", n = 10000)
object.size(base_10000[[3]])
new_list <- SplitDF(base_10000[[3]])
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
new_list <- SplitDF(base_10000[[3]])
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
new_list <- SplitDF(base_10000[[3]])
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
object.size(base_10000[[3]])/10^6
base_files <- LoadFiles("data/en_US/")
new_list <- SplitDF(base_files[[3]])
new_list
df <- base_files[[3]]
head(df)
object.size(df)/10^6
object.size(df)/10^6 %>% as.integer() / 50
object.size(df) %>% as.numeric()/10^6 %>% as.integer() / 50
object.size(df) %>% as.numeric()/10^6 %>% as.integer() / 50 %>% +1
object.size(df) %>% as.numeric()/10^6 %>% as.integer() / 50
chunks <- object.size(df) %>% as.numeric()/10^6 %>% as.integer() / 50
chunks <- chunks + 1
chunks
chunks <- as.integer(chunks)
chunks
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
chunks
N <- as.integer(nrow(df) / chunks) + 1
N
df_list <- str(split(df, (as.numeric(nrow(df) - 1) %?% N)))
df_list <- str(split(df, (as.numeric(nrow(df) - 1) %/% N)))
df_list[[1]]
df_list[1]
str(split(df, (as.numeric(nrow(df) - 1) %/% N)))
str(split(df, (as.numeric(rownames(df))-1) %/% as.integer(nrow(df)/8)))
new_list <- str(split(df, (as.numeric(rownames(df))-1) %/% as.integer(nrow(df)/8)))
new_list
new_list <- split(df, (as.numeric(rownames(df))-1) %/% as.integer(nrow(df)/8))
new_list
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
chunks <- lapply(base_files, SplitDF)
chunks
View(chunks)
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
str(SplitDFbase_files[[3]])
str(SplitDF(base_files[[3]]))
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
str(SplitDF(base_files[[3]]))
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
str(SplitDF(base_files[[3]]))
base_chunks <- lapply(base_files, SplitDF)
View(base_chunks)
base_chunks <- unlist(base_chunks, recursive = F)
View(base_files)
View(base_chunks)
base_chunks <- lapply(base_files, SplitDF) %>% unlist(recursive = F)
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
df <- base_chunks[[1]]
df
sapply(initial_result$features , '[[', "POS") %>% table
sapply(initial_result$features , '[[', "POS") %>% table
source("~/.active-rstudio-document", echo=TRUE)
df[1]
df[2]
df[2,1]
df[2,2]
df[2,3]
df[1,2]
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
initial_result
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .)
initial_result
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator()))
initial_result
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
sapply(initial_result$features , '[[', "POS") %>% table
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
sapply(initial_result$features , '[[', "POS")
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
sapply(initial_result$features , '[[', "POS") %>% table
string = df[1, 2]
initial_result = string %>%
annotate(list(Maxent_Sent_Token_Annotator(),
Maxent_Word_Token_Annotator())) %>%
annotate(string, Maxent_POS_Tag_Annotator(), .) %>%
subset(type=='word')
sapply(initial_result$features , '[[', "POS")
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
df
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
rm(list = ls())
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
source("~/.active-rstudio-document", echo=TRUE)
base_1000 <- LoadFiles("data/en_US/", n = 1000)
df <- base_1000[[3]]
df
source("~/.active-rstudio-document", echo=TRUE)
df
df_pos <- CleanTokens(df, n = 1)
df_pos
df_pos %>% group_by(word) %>% summarise(total = n(word))
df_pos %>% group_by(word) %>% summarise(total = n())
df_pos %>% group_by(word) %>% summarise(total = n()) %>% qplot()
df_pos %>% group_by(word) %>% summarise(total = n()) %>% barplot()
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
df
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
5e6
as.numeric(5e6)
as.integer(5e6)
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper_functions.R")
base_ch <- UnlistDF(base_1000, size = 2e6)
View(base_ch)
View(base_1000)
Unlist(base_1000, size = 2e6)
UnlistDF(base_1000, size = 2e6)
UnlistDF(base_1000, size = 1e6)
SplitDF(base_1000[[3]], size = 5e6)
SplitDF(base_1000[[3]], size = 1e6)
SplitDF(base_1000[[3]], size = 1e5)
SplitDF(base_1000[[3]], size = 5e4)
base_ch <- UnlistDF(base_1000, size = 5e4)
View(base_ch)
base_ch <- UnlistDF(base_1000, size = 5e4) %>% MergeDTM()
View(base_ch)
base_ch <- UnlistDF(base_1000, size = 5e4) %>% lapply(POSsumDF) %>% MergeDTM()
View(base_ch)
library(htmlTable)
library(htmltools)
library(htmlwidgets)
install.packages("htmltools")
install.packages(c("bslib", "coin", "diffobj", "digest", "Hmisc", "lubridate", "mgcv", "mvtnorm", "RcppArmadillo", "readr", "shiny", "stringi", "testthat", "tibble", "tidymodels", "tidyr", "tidytext", "xfun"))
install.packages(c("bslib", "coin", "diffobj", "digest", "Hmisc", "lubridate", "mgcv", "mvtnorm", "RcppArmadillo", "readr", "shiny", "stringi", "testthat", "tibble", "tidymodels", "tidyr", "tidytext", "xfun"))
