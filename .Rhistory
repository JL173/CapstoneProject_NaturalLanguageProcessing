filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
predictions
Predict("sos in the", twitter_model, ngram = 3, gamma = 0.5)
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### Back-off implementation
known_bigrams <- bigrams %>% anti_join(known_trigrams, by = c("word2" = "word3")) %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
predictions
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### Back-off implementation
known_bigrams <- bigrams %>% anti_join(known_trigrams, by = c("word2" = "word3")) %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
View(unob_trigrams)
# all unobserved trigram tails
unob_trigrams <- anti_join(bigrams, known_trigrams,
by = c("word2" = "word3"))
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(bigrams, known_trigrams,
by = c("word2" = "word3"))
### Back-off implementation
known_bigrams <- unob_trigrams %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
Predict("sos in the", twitter_model, ngram = 2, gamma = 0.5)
Predict("sos in the", twitter_model, ngram = 2, gamma = 0.5)
View(unob_bigrams)
View(known_bigrams)
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(bigrams, known_trigrams,
by = c("word2" = "word3"))
### Back-off implementation
known_bigrams <- unob_trigrams %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2")) %>%
anti_join(known_trigrams, by = c("word1" = "word3"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper2.R")
Predict("sos in the", twitter_model, ngram = 2, gamma = 0.5)
Predict("sos in the", twitter_model, ngram = 3, gamma = 0.5)
str <- c("sos", "in", "the")
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### ### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
str <- c("sos", "in", "the")
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### ### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
str <- c("sos", "in", "the")
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(trigrams, known_quagrams,
by = c("word3" = "word4"))
### Back-off implementation
known_trigrams <- unob_quagrams %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(bigrams, known_trigrams,
by = c("word2" = "word3")) %>%
anti_join(known_quagrams, by = c("word2" = "word4"))
### ### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2")) %>%
anti_join(known_trigrams, by = c("word1" = "word3")) %>%
anti_join(known_quagrams, by = c("word1" = "word4"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
str <- c("sos", "in", "the")
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(trigrams, known_quagrams,
by = c("word3" = "word4"))
### Back-off implementation
known_trigrams <- unob_quagrams %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(bigrams, known_trigrams,
by = c("word2" = "word3")) %>%
anti_join(known_quagrams, by = c("word2" = "word4"))
### ### Back-off implementation
known_bigrams <- unob_trigrams %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2")) %>%
anti_join(known_trigrams, by = c("word1" = "word3")) %>%
anti_join(known_quagrams, by = c("word1" = "word4"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
print(sum(predictions$P))
predictions
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper2.R")
Predict("sos in the", twitter_model, ngram = 3, gamma = 0.5)
Predict("sos in the", twitter_model, ngram = 3, gamma = 0.5)
for (string in test_strings2){
Predict(string, twitter_model, ngram = 3, gamma = 0.5) %>% head(10)
}
for (string in test_strings2){
results <- Predict(string, twitter_model, ngram = 3, gamma = 0.5) %>% head(10)
str(results)
}
for (string in test_strings2){
results <- Predict(string, twitter_model, ngram = 3, gamma = 0.5) %>% head(10)
results
}
for (string in test_strings2){
results <- Predict(string, twitter_model, ngram = 3, gamma = 0.5) %>% head(10)
print(results)
}
base_files <- LoadFiles("data/en_US/10/")
full_unigrams <- CleanTokens(base_files, n = 1) %>%
WordFreq() %>%
filter(freq > 1)
source("C:/Users/JL/Desktop/Study/Coursera/Johns Hopkins Data Science/10 capstone/CapstoneProject_NaturalLanguageProcessing/helper2.R")
full_unigrams <- CleanTokens(base_files, n = 1) %>%
WordFreq() %>%
filter(freq > 1)
full_unigrams <- lapply(base_files, CleanTokens(base_files, n = 1)) %>%
MergeDTM() %>%
WordFreq() %>%
filter(freq > 1)
full_unigrams <- lapply(base_files, CleanTokens, n = 1) %>%
MergeDTM() %>%
WordFreq() %>%
filter(freq > 1)
full_bigrams <- lapply(base_files, CleanTokens, n = 2) %>%
MergeDTM() %>%
WordFreq() %>%
filter(freq > 1)
full_trigrams <- lapply(base_files, CleanTokens, n = 3) %>%
MergeDTM() %>%
WordFreq() %>%
filter(freq > 1)
full_quagrams <- lapply(base_files, CleanTokens, n = 4) %>%
MergeDTM() %>%
WordFreq() %>%
filter(freq > 1)
full_model_10 <- CreateFreqTable(full_unigrams, full_bigrams,
full_trigrams, full_quagrams)
for (string in test_strings2){
results <- Predict(string, full_model_10, ngram = 3, gamma = 0.5) %>% head(10)
print(results)
}
View(full_unigrams)
View(full_bigrams)
View(full_trigrams)
View(full_quagrams)
