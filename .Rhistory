quagrams <- twitter_model %>%
filter(!is.na(word4))
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
test_bigrams <- bigrams %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
View(test_bigrams)
View(unob_quagrams)
View(known_trigrams)
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3")) %>%
rbind(unob_quagrams)
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3")) %>%
rbind(unob_quagrams)
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2")) %>%
rbind(unob_trigrams)
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
View(unob_bigrams)
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3")) %>%
rbind(unob_quagrams)
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
View(unob_trigrams)
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3")) %>%
rbind(unob_quagrams) %>% group_by(word1)
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
known_quagrams <- quagrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3], !is.na(word4))
trigram_sum <- trigrams %>%
filter(word1 == str[1], word2 == str[2], word3 == str[3])
trigram_sum <- trigram_sum$freq
# P for known quagrams
known_quagrams$P <- (known_quagrams$freq - gamma) / trigram_sum
# P-density for unobserved quagrams
alpha1 <- 1 - sum(known_quagrams$P)
# all unobserved quagram tails
unob_quagrams <- anti_join(unigrams, known_quagrams,
by = c("word1" = "word4"))
### Back-off implementation
known_trigrams <- trigrams %>%
semi_join(unob_quagrams, by = c("word3" = "word1")) %>%
filter(word1 == str[2], word2 == str[3], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[2], word2 == str[3])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha2 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3")) %>%
rbind(unob_quagrams) %>% group_by(word1) %>% summarise(freq = sum(freq))
### ### Back-off implementation
known_bigrams <- bigrams %>%
semi_join(unob_trigrams, by = c("word2" = "word1")) %>%
filter(word1 == str[3], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[3])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha3 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[3]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha3 * (unob_bigrams$freq / unob_sum)
### ### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha2 * bigram_predictions$P
### ###
trigram_predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
trigram_predictions$P <- alpha1 * trigram_predictions$P
###
predictions <- rbind(known_quagrams, trigram_predictions) %>%
arrange(desc(P))
predictions
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
predictions
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
predictions
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
gamma = 0.5
unigrams <- twitter_model %>%
filter(!is.na(word1), is.na(word2))
bigrams <- twitter_model %>%
filter(!is.na(word2), is.na(word3))
trigrams <- twitter_model %>%
filter(!is.na(word3), is.na(word4))
quagrams <- twitter_model %>%
filter(!is.na(word4))
str <- c("in", "the")
known_trigrams <- trigrams %>%
filter(word1 == str[1], word2 == str[2], !is.na(word3), is.na(word4))
bigram_sum <- bigrams %>%
filter(word1 == str[1], word2 == str[2])
bigram_sum <- bigram_sum$freq
# P for known trigrams
known_trigrams$P <- (known_trigrams$freq - gamma) / bigram_sum
# P-density for unobserved trigrams
alpha1 <- 1 - sum(known_trigrams$P)
# all unobserved trigram tails
unob_trigrams <- anti_join(unigrams, known_trigrams,
by = c("word1" = "word3"))
### Back-off implementation
known_bigrams <- bigrams %>%
filter(word1 == str[2], !is.na(word2), is.na(word3))
unigram_sum <- unigrams %>%
filter(word1 == str[2])
unigram_sum <- unigram_sum$freq
# P for known bigrams
known_bigrams$P <- (known_bigrams$freq - gamma) / unigram_sum
# p-density for unobserved bigrams
alpha2 <- 1 - sum(known_bigrams$P)
# all unobserved bigram tails
unob_bigrams <- anti_join(unigrams, known_bigrams,
by = c("word1" = "word2"))
### ### Back-off implementation
# formatting
unob_bigrams$word2 <- unob_bigrams$word1
unob_bigrams$word1 <- str[2]
# probability of unobserved bigrams
unob_sum <- sum(unob_bigrams$freq)
unob_bigrams$P <- alpha2 * (unob_bigrams$freq / unob_sum)
### ###
# collect into one data.table
bigram_predictions <- rbind(known_bigrams, unob_bigrams) %>%
arrange(desc(P))
bigram_predictions$P <- alpha1 * bigram_predictions$P
###
predictions <- rbind(known_trigrams, bigram_predictions) %>%
arrange(desc(P))
predictions
